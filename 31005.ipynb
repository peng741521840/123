{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "31005.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbRXe9x7MswpnIjjQNNxHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peng741521840/123/blob/main/31005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbheEJEDpOZ2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math, sys, os"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRFYDYshrDvJ",
        "outputId": "972c8e24-ed3f-4fdc-fa48-2f7d2cde7875"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Authorization code: 4/1AX4XfWhn5wIrLQEzSZKjU8HrAnrw9TzZyKrc4VXnpwljVj-k9W-q8_Egjbs"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM0jp3JmrzPX"
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/Colab Notebooks/iris.data')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts8-EpyUptak"
      },
      "source": [
        "def dataProcess(source_fpath, target_fpath):\n",
        "    with open(source_fpath) as source_f:\n",
        "        sample_list = []\n",
        "        for line in source_f:\n",
        "            content = line.strip().split(\",\")\n",
        "            sample_list.append(np.array(content))\n",
        "        csvdf = pd.DataFrame(sample_list)\n",
        "        csvdf.columns = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Class\"]\n",
        "        csvdf.to_csv(target_fpath, index=0)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6lFO2JopTfB"
      },
      "source": [
        "def informationEntropy(dataset):\n",
        "    entropysum = 0\n",
        "    category_list = list(dataset[\"Class\"])\n",
        "    for category in set(dataset[\"Class\"]):\n",
        "        pk = category_list.count(category) / len(dataset)\n",
        "        entropysum += pk * math.log(pk, 2)\n",
        "    return (-1) * entropysum"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f5F0JYxT5j0"
      },
      "source": [
        "def informationDiscreteGain(dataset, attribute):\n",
        "    entropy = informationEntropy(dataset)\n",
        "    entropysum = 0\n",
        "    attribute_value_list = list(dataset[attribute])\n",
        "    for attribute_value in set(dataset[attribute]):\n",
        "        weight = attribute_value_list.count(attribute_value) / len(dataset)\n",
        "        entropysum += weight * informationEntropy(dataset[dataset[attribute] == attribute_value])\n",
        "    return entropy - entropysum"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eys8IPEZqPI2"
      },
      "source": [
        "def informationContinuousGain(dataset, attribute):\n",
        "    entropy = informationEntropy(dataset)\n",
        "    attribute_value_list = sorted(set(dataset[attribute]))\n",
        "    if len(attribute_value_list) == 1:\n",
        "        thresholds = [attribute_value_list[0]]\n",
        "    else:\n",
        "        thresholds = [(attribute_value_list[i] + attribute_value_list[i + 1]) / 2 for i in range(len(attribute_value_list) - 1)]\n",
        "    \n",
        "    threshold_entropysum_dict = {}\n",
        "    for threshold in thresholds:\n",
        "        lessthreshold = dataset[dataset[attribute] <= threshold]\n",
        "        morethreshold = dataset[dataset[attribute] > threshold]\n",
        "        lessweight = len(lessthreshold) / len(dataset)\n",
        "        moreweight = len(morethreshold) / len(dataset)\n",
        "        entropysum = lessweight * informationEntropy(lessthreshold) + moreweight * informationEntropy(morethreshold)\n",
        "        threshold_entropysum_dict[threshold] = entropysum\n",
        "        \n",
        "    threshold_entropysum_sorted = sorted(threshold_entropysum_dict.items(), key=lambda item: item[1])\n",
        "    minentropysum_threshold = threshold_entropysum_sorted[0][0]\n",
        "    minentropysum = threshold_entropysum_sorted[0][1]\n",
        "    return minentropysum_threshold, entropy - minentropysum"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LreGQMotpbZS"
      },
      "source": [
        "def maxNumOutcome(dataset):\n",
        "    category_list = list(dataset[\"Class\"])\n",
        "    category_dict = {}\n",
        "    for category in set(dataset[\"Class\"]):\n",
        "        category_dict[category] = category_list.count(category)\n",
        "    category_sorted = sorted(category_dict.items(), key=lambda item: item[1], reverse=True)\n",
        "    return category_sorted[0][0]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k80rZtCtpgZO"
      },
      "source": [
        "def treeNodeGenerate(dataset, attribute_list):\n",
        "    if len(set(dataset[\"Class\"])) == 1:\n",
        "        node = list(set(dataset[\"Class\"]))[0]\n",
        "    elif len(attribute_list) == 0 or sum([len(set(dataset[attribute])) - 1 for attribute in attribute_list]) == 0:\n",
        "        node = maxNumOutcome(dataset)\n",
        "    else:\n",
        "        attribute_gain_dict = {}\n",
        "        for attribute in attribute_list:\n",
        "            threshold, attribute_gain = informationContinuousGain(dataset, attribute)\n",
        "            attribute_gain_dict[attribute] = threshold, attribute_gain\n",
        "        attribute_gain_sorted = sorted(attribute_gain_dict.items(), key=lambda item: item[1][1], reverse=True)\n",
        "        maxgain_attribute = attribute_gain_sorted[0][0]\n",
        "        maxgain_threshold = attribute_gain_sorted[0][1][0]\n",
        "\n",
        "        son_node_attribute_list = attribute_list.copy()\n",
        "        son_node_attribute_list.remove(maxgain_attribute)\n",
        "\n",
        "        left_node_dataset = dataset[dataset[maxgain_attribute] <= maxgain_threshold]\n",
        "        if len(left_node_dataset) == 0:\n",
        "            leftnode = maxNumOutcome(dataset)\n",
        "        else:\n",
        "            leftnode = treeNodeGenerate(left_node_dataset, son_node_attribute_list)\n",
        "        \n",
        "        right_node_dataset = dataset[dataset[maxgain_attribute] > maxgain_threshold]\n",
        "        if len(right_node_dataset) == 0:\n",
        "            rightnode = maxNumOutcome(dataset)\n",
        "        else:\n",
        "            rightnode = treeNodeGenerate(right_node_dataset, son_node_attribute_list)\n",
        "        \n",
        "        if leftnode == rightnode:\n",
        "            node = leftnode\n",
        "        else:\n",
        "            node = {}\n",
        "            node[(maxgain_attribute, maxgain_threshold)] = {\"<=\":leftnode, \">\":rightnode}\n",
        "\n",
        "    return node"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RrqEs6Ppi1x"
      },
      "source": [
        "def predictOne(tree_train_model, testdata):\n",
        "    if type(tree_train_model) == str:\n",
        "        predict_value = tree_train_model\n",
        "    elif type(tree_train_model) == dict:\n",
        "        key = list(tree_train_model)[0]\n",
        "        if testdata[key[0]] <= key[1]:\n",
        "            son_tree_train_model = tree_train_model[key][\"<=\"]\n",
        "        else:\n",
        "            son_tree_train_model = tree_train_model[key][\">\"]\n",
        "        predict_value = predictOne(son_tree_train_model, testdata)\n",
        "    return predict_value"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlMpZ8r2pkC8"
      },
      "source": [
        "def predict(tree_train_model, testdataset):\n",
        "    predict_list = []\n",
        "    for i in range(len(testdataset)):\n",
        "        predict_value = predictOne(tree_train_model, testdataset.loc[i])\n",
        "        predict_list.append((testdataset.loc[i][\"Class\"], predict_value))\n",
        "    return predict_list"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cadrgq_pplJv"
      },
      "source": [
        "def predictAccuracy(predict_list):\n",
        "    predict_true_num = 0\n",
        "    for bigram in predict_list:\n",
        "        if bigram[0] == bigram[1]:\n",
        "            predict_true_num += 1\n",
        "    accuracy = predict_true_num / len(predict_list)\n",
        "    return accuracy"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiw_dfCpm4z"
      },
      "source": [
        "def subdatasetPartitioning(dataset):\n",
        "    index = [i for i in range(len(dataset))]\n",
        "    np.random.seed(2)\n",
        "    np.random.shuffle(index)\n",
        "\n",
        "    traindatasetlen = int(len(dataset) * 0.8)\n",
        "    traindataset = dataset.loc[index[:traindatasetlen]]\n",
        "    testdataset = dataset.loc[index[traindatasetlen:]]\n",
        "\n",
        "    return traindataset, testdataset"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo9C45OUpn8p"
      },
      "source": [
        "def datasetPartitioning(dataset):\n",
        "\n",
        "    traindataset_list = []\n",
        "    testdataset_list = []\n",
        "    for i in range(3):\n",
        "        subdataset = dataset.loc[i * 50 : (i + 1) * 50 - 1]\n",
        "        subdataset = subdataset.reset_index()\n",
        "        subtraindataset, subtestdataset = subdatasetPartitioning(subdataset)\n",
        "        traindataset_list.append(subtraindataset)\n",
        "        testdataset_list.append(subtestdataset)\n",
        "\n",
        "    traindataset = pd.concat(traindataset_list, ignore_index=True)\n",
        "    testdataset = pd.concat(testdataset_list, ignore_index=True)\n",
        "\n",
        "    return traindataset, testdataset"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZXFq2azppka",
        "outputId": "c070564e-8450-479c-d838-fb67fc4f5b67"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    source_fpath = \"iris.data\"\n",
        "    target_fpath = source_fpath.replace(\"data\", \"csv\")\n",
        "    dataProcess(source_fpath, target_fpath)\n",
        "\n",
        "    dataset = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "    traindataset, testdataset =  datasetPartitioning(dataset)\n",
        "\n",
        "    attribute_list = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
        "    tree_train_model = treeNodeGenerate(traindataset, attribute_list)\n",
        "    print(\"The Dict of Trained Model:\")\n",
        "    print(tree_train_model, \"\\n\")\n",
        "\n",
        "    predict_list = predict(tree_train_model, testdataset)\n",
        "    print(\"The List of Predicting Outcomes (Actual Label, Predicted Value) :\")\n",
        "    print(predict_list, \"\\n\")\n",
        "\n",
        "    print(\"The Accuracy of Model Prediction: \", predictAccuracy(predict_list))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Dict of Trained Model:\n",
            "{('PetalLength', 2.45): {'<=': 'Iris-setosa', '>': {('PetalWidth', 1.75): {'<=': {('SepalLength', 4.95): {'<=': 'Iris-virginica', '>': 'Iris-versicolor'}}, '>': {('SepalLength', 5.95): {'<=': {('SepalWidth', 3.0): {'<=': 'Iris-virginica', '>': 'Iris-versicolor'}}, '>': 'Iris-virginica'}}}}}} \n",
            "\n",
            "The List of Predicting Outcomes (Actual Label, Predicted Value) :\n",
            "[('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-setosa', 'Iris-setosa'), ('Iris-versicolor', 'Iris-virginica'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-versicolor', 'Iris-versicolor'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica'), ('Iris-virginica', 'Iris-virginica')] \n",
            "\n",
            "The Accuracy of Model Prediction:  0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}